# -*- coding: utf-8 -*-
"""forcasting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QXBbsJmNK5XzfpM93gTT-gXpIhF9jl1e
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("Final_Cement_Dataset.csv",index_col = 'Date',parse_dates=True)
df.head()

df.info()

train_size = int(df.shape[0]*0.9)
test_size = int(df.shape[0]*0.95)

train_size, test_size

X_train = df[:train_size].drop("month", axis=1)
X_test = df[train_size:test_size].drop("month", axis=1)
X_val = df[test_size:].drop("month", axis=1)

y_train = df[:train_size]["month"]
y_test = df[train_size:test_size]["month"]
y_val = df[test_size:]["month"]

X_train.shape, X_test.shape, X_val.shape

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

import lightgbm

model = lightgbm.LGBMRegressor()

model.fit(X_train, y_train)

preds = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(preds, y_test))
r2 = r2_score(preds, y_test)
print(f"RMSE Score = {rmse}\nR2 Score = {r2}")

preds = model.predict(X_val)
rmse = np.sqrt(mean_squared_error(preds, y_val))
r2 = r2_score(preds, y_val)
print(f"RMSE Score = {rmse}\nR2 Score = {r2}")

from sklearn.svm import SVR  #Support Vector Regression

model = SVR()
model.fit(X_train, y_train)

preds = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(preds, y_test))
r2 = r2_score(preds, y_test)
print(f"RMSE Score = {rmse}\nR2 Score = {r2}")

from sklearn.neighbors import KNeighborsRegressor

model = KNeighborsRegressor()

model.fit(X_train, y_train)

preds = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(preds, y_test))
r2 = r2_score(preds, y_test)
print(f"RMSE Score = {rmse}\nR2 Score = {r2}")

# !pip install tensorflow

import tensorflow as tf

BATCH_SIZE = 64
BUFFER_SIZE = 100
WINDOW_LENGTH = 24

def window_data(X, Y, window=7):
    '''
    The dataset length will be reduced to guarante all samples have the window, 
    so new length will be len(dataset)-window
    '''
    x = []
    y = []
    for i in range(window-1, len(X)):
        x.append(X[i-window+1:i+1])
        y.append(Y[i])
    return np.array(x), np.array(y)


# Since we are doing sliding, we need to join the datasets again of train and test
X_w = np.concatenate((X_train, X_test))
y_w = np.concatenate((y_train, y_test))

X_w, y_w = window_data(X_w, y_w, window=WINDOW_LENGTH)
X_train_w = X_w[:-len(X_test)]
y_train_w = y_w[:-len(X_test)]
X_test_w = X_w[-len(X_test):]
y_test_w = y_w[-len(X_test):]

# Check we will have same test set as in the previous models, make sure we didnt screw up on the windowing
print(f"Test set equal: {np.array_equal(y_test_w,y_test)}")

train_data = tf.data.Dataset.from_tensor_slices((X_train_w, y_train_w))
train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()

val_data = tf.data.Dataset.from_tensor_slices((X_test_w, y_test_w))
val_data = val_data.batch(BATCH_SIZE).repeat()

dropout = 0.0
model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(
        128, input_shape=X_train_w.shape[-2:], dropout=dropout),
    tf.keras.layers.Dense(128),
    tf.keras.layers.Dense(128),
    tf.keras.layers.Dense(1)
])

model.compile(optimizer='rmsprop', loss='mae')

EVALUATION_INTERVAL = 200
EPOCHS = 15

model_history = model.fit(train_data, epochs=EPOCHS,
                                      steps_per_epoch=EVALUATION_INTERVAL,
                                      validation_data=val_data, validation_steps=50)  # ,callbacks=[tensorboard_callback]) #Uncomment this line for tensorboard support

preds = model.predict(X_test_w).reshape(1, -1)[0]
rmse = np.sqrt(mean_squared_error(preds, y_test))
r2 = r2_score(preds, y_test)
print(f"RMSE Score = {rmse}\nR2 Score = {r2}")

import pandas as pd
from statsmodels.tsa.vector_ar.var_model import VAR

df = pd.read_csv("Final_Cement_Dataset.csv",index_col = 'Date',parse_dates=True)
df.head()

train_size = int(df.shape[0]*0.9)
test_size = int(df.shape[0]*0.95)

train_size, test_size

X_train = df[:train_size].drop("month", axis=1)
X_test = df[train_size:test_size].drop("month", axis=1)
X_val = df[test_size:].drop("month", axis=1)

y_train = df[:train_size]["month"]
y_test = df[train_size:test_size]["month"]
y_val = df[test_size:]["month"]



model = VAR(X_train)
model_fit = model.fit()

preds = model.predict(model_fit.params, end=len(X_test))

preds_df = pd.DataFrame(preds, columns=X_train.columns)

test_temporary = pd.Series(X_test["Sales"].values, range(len(X_train),len(X_train)+len(X_test)))
pred_temporary = pd.Series(preds_df["Sales"].values, range(len(X_train),len(X_train)+len(X_test)))

plt.figure(figsize=(30,10))
plt.plot(X_train["Sales"].values, label="Train")
plt.plot(test_temporary, label="Real",marker=".", alpha=0.8)
plt.plot(pred_temporary, label="Predicted", marker="o", alpha=0.8)
plt.legend()
plt.show()





